{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "This notebook is a demonstration of training workflow for NN correcting model error accompanying: Chen, Tse-Chun, Stephen G. Penny, Jeffrey S. Whitaker, Sergey Frolov, Robert Pincus, and Stefan Tulich. “Correcting Systematic and State-Dependent Errors in the NOAA FV3-GFS Using Neural Networks.” In Prep.\n",
    "\n",
    "## Evironment\n",
    "- linux cluster with slurm scheduler\n",
    "- limited GPU access time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-poster')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare reduced dataset:\n",
    "- requires climate data operator ([CDO](https://code.mpimet.mpg.de/projects/cdo/wiki/Cdo#Documentation)) package for gridded data reduction\n",
    "- run command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 30 23:05:44 PST 2023\n",
      "2019122000 convert to low res\n",
      "2019122006 convert to low res\n",
      "2019122012 convert to low res\n",
      "2019122018 convert to low res\n",
      "Mon Jan 30 23:05:44 PST 2023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"bash reduce_dataset.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- takes about 15 mins\n",
    "- output expected in “./sample_nc/2019122000/”, if not already exists.\n",
    "    - bfg_2019122000_fhr06_control_sub\n",
    "    - bfg_2019122000_fhr06_control_low\n",
    "    - sfg_2019122000_fhr06_control_sub\n",
    "    - sfg_2019122000_fhr06_control_low\n",
    "    - sfg_2019122000_fhr00_control_sub\n",
    "    - sfg_2019122000_fhr00_control_low\n",
    "    - control/INPUT/fv3_increment6.nc_sub\n",
    "    - control/INPUT/fv3_increment6.nc_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sample_nc/2019122000/bfg_2019122000_fhr06_control_low\n",
      "./sample_nc/2019122000/bfg_2019122000_fhr06_control_sub\n",
      "./sample_nc/2019122000/control/INPUT/fv3_increment6.nc_low\n",
      "./sample_nc/2019122000/control/INPUT/fv3_increment6.nc_sub\n",
      "./sample_nc/2019122000/sfg_2019122000_fhr00_control_low\n",
      "./sample_nc/2019122000/sfg_2019122000_fhr00_control_sub\n",
      "./sample_nc/2019122000/sfg_2019122000_fhr06_control_low\n",
      "./sample_nc/2019122000/sfg_2019122000_fhr06_control_sub\n"
     ]
    }
   ],
   "source": [
    "!ls ./sample_nc/2019122000/*_control_* ./sample_nc/2019122000/control/INPUT/*nc_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset into numpy arrays\n",
    "\n",
    "- requires python packages: joblib, pandas, xarray, numpy\n",
    "- takes reduced dataset in nc format to numpy array files\n",
    "- run command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlat=32, nlon=64\n",
      "sfc size: 31, var in size: 1398, var out size: 890, date size: 3\n",
      "2019-12-20 00:00:00\n",
      "2019-12-20 06:00:00\n",
      "2019-12-20 12:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"python preprocess.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output expected in “./npys/”\n",
    "    - ifs_f06_ranl_low\n",
    "    - ifs_f06_ranl_sub\n",
    "    - ifs_out_ranl_low\n",
    "    - ifs_out_ranl_sub\n",
    "    - ifs_sfc_ranl_low\n",
    "    - ifs_sfc_ranl_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./npys/ifs_f06_ranl_low  ./npys/ifs_out_ranl_low  ./npys/ifs_sfc_ranl_low\n",
      "./npys/ifs_f06_ranl_sub  ./npys/ifs_out_ranl_sub  ./npys/ifs_sfc_ranl_sub\n"
     ]
    }
   ],
   "source": [
    "!ls ./npys/ifs*ranl_???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mean and std profile for normalization\n",
    "\n",
    "- requires python packages: numpy\n",
    "- computed from the previously produced numpy files\n",
    "- run command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python get_mean_std.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output expected in \"./npys\"\n",
    "    - ifs_sfc_ranl_sub_std_1d.npy\n",
    "    - ifs_sfc_ranl_sub_mean_1d.npy\n",
    "    - ifs_sfc_ranl_low_std_1d.npy\n",
    "    - ifs_sfc_ranl_low_mean_1d.npy\n",
    "    - ifs_out_ranl_sub_std_1d.npy\n",
    "    - ifs_out_ranl_sub_mean_1d.npy\n",
    "    - ifs_out_ranl_low_std_1d.npy\n",
    "    - ifs_out_ranl_low_mean_1d.npy\n",
    "    - ifs_f06_ranl_sub_std_1d.npy\n",
    "    - ifs_f06_ranl_sub_mean_1d.npy\n",
    "    - ifs_f06_ranl_low_std_1d.npy\n",
    "    - ifs_f06_ranl_low_mean_1d.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./npys/ifs_f06_ranl_low_mean_1d.npy  ./npys/ifs_out_ranl_sub_mean_1d.npy\n",
      "./npys/ifs_f06_ranl_low_std_1d.npy   ./npys/ifs_out_ranl_sub_std_1d.npy\n",
      "./npys/ifs_f06_ranl_sub_mean_1d.npy  ./npys/ifs_sfc_ranl_low_mean_1d.npy\n",
      "./npys/ifs_f06_ranl_sub_std_1d.npy   ./npys/ifs_sfc_ranl_low_std_1d.npy\n",
      "./npys/ifs_out_ranl_low_mean_1d.npy  ./npys/ifs_sfc_ranl_sub_mean_1d.npy\n",
      "./npys/ifs_out_ranl_low_std_1d.npy   ./npys/ifs_sfc_ranl_sub_std_1d.npy\n"
     ]
    }
   ],
   "source": [
    "!ls ./npys/*1d.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit training program\n",
    "\n",
    "- requires python packages: pandas, xarray, numpy, torch\n",
    "- run command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:There are 4 of combinations!!\n",
      "INFO:root:No jobs running currently!\n",
      "INFO:root:running ids: []\n",
      "INFO:root:total running ids: 0\n",
      "INFO:root:skipping still running combinations: 0\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done   2 out of   4 | elapsed:    0.9s remaining:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done   4 out of   4 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done   4 out of   4 | elapsed:    1.0s finished\n",
      "INFO:root:Took 0.9600720405578613s to scan through all combinations\n",
      "INFO:root:4/4 training to be (re)submitted\n",
      "INFO:root:There are 0.5 of batches!!\n",
      "INFO:root:submitting to jobid: 0\n",
      "sh: /home/Sergey.Frolov/work/model_error/code/model_error_correction/slurm_out/job000.py.out: Permission denied\n",
      "Submitted batch job 41618510\n"
     ]
    }
   ],
   "source": [
    "!mkdir jobs\n",
    "!mkdir slurm_out\n",
    "!python submit_monitor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this will produce “./jobs/job000.py” and from it, submit (via slurm) 8 training tasks to 1 node (1 gpu for each)\n",
    "- takes about 1 min to finish this training example.\n",
    "- expect training checkpoint files in \"./checks/\". they will be updated during training.\n",
    "- the checkpoint files are named using the specified hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checks/conv2d_tpsuvq_subset-cyc_q_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "./checks/conv2d_tpsuvq_subset-cyc_q_2_1_128_2_0.25_8_mse_1e-05_0.05_sub\n",
      "./checks/conv2d_tpsuvq_subset-cyc_t_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "./checks/conv2d_tpsuvq_subset-cyc_t_2_1_128_2_0.25_8_mse_1e-05_0.05_sub\n",
      "./checks/conv2d_tpsuvq_subset-cyc_u_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "./checks/conv2d_tpsuvq_subset-cyc_u_2_1_128_2_0.25_8_mse_1e-05_0.05_sub\n",
      "./checks/conv2d_tpsuvq_subset-cyc_v_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "./checks/conv2d_tpsuvq_subset-cyc_v_2_1_128_2_0.25_8_mse_1e-05_0.05_sub\n"
     ]
    }
   ],
   "source": [
    "!ls ./checks/conv2d*_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Load some more packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from check_model import sub_collect_models, sub_eval_model, sub_saliency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect hyperparameters and training status for all trained model\n",
    "* run command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:reading df from file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.72 ms, sys: 414 µs, total: 3.14 ms\n",
      "Wall time: 2.39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if_renew=False\n",
    "df = sub_collect_models(if_renew=if_renew, df='df_low-res-config', if_wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- takes about 30s\n",
    "- results will be in data frame format. return as df and saved.\n",
    "- expect output \"df_low-res-config\" in \"./checks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checks/df_low-res-config\n"
     ]
    }
   ],
   "source": [
    "!ls ./checks/df*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>vars_f06</th>\n",
       "      <th>vars_sfc</th>\n",
       "      <th>vars_out</th>\n",
       "      <th>testset</th>\n",
       "      <th>kernel_sizes</th>\n",
       "      <th>channels</th>\n",
       "      <th>n_conv</th>\n",
       "      <th>p</th>\n",
       "      <th>bs</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>wd</th>\n",
       "      <th>trunc</th>\n",
       "      <th>filename</th>\n",
       "      <th>epoches</th>\n",
       "      <th>impatience</th>\n",
       "      <th>valid_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conv2d</td>\n",
       "      <td>tpsuvq</td>\n",
       "      <td>subset-cyc</td>\n",
       "      <td>q</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sub</td>\n",
       "      <td>/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conv2d</td>\n",
       "      <td>tpsuvq</td>\n",
       "      <td>subset-cyc</td>\n",
       "      <td>q</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sub</td>\n",
       "      <td>/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conv2d</td>\n",
       "      <td>tpsuvq</td>\n",
       "      <td>subset-cyc</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sub</td>\n",
       "      <td>/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conv2d</td>\n",
       "      <td>tpsuvq</td>\n",
       "      <td>subset-cyc</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sub</td>\n",
       "      <td>/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conv2d</td>\n",
       "      <td>tpsuvq</td>\n",
       "      <td>subset-cyc</td>\n",
       "      <td>u</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sub</td>\n",
       "      <td>/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>conv2d</td>\n",
       "      <td>tpsuvq</td>\n",
       "      <td>subset-cyc</td>\n",
       "      <td>u</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sub</td>\n",
       "      <td>/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>conv2d</td>\n",
       "      <td>tpsuvq</td>\n",
       "      <td>subset-cyc</td>\n",
       "      <td>v</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sub</td>\n",
       "      <td>/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>conv2d</td>\n",
       "      <td>tpsuvq</td>\n",
       "      <td>subset-cyc</td>\n",
       "      <td>v</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sub</td>\n",
       "      <td>/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type vars_f06    vars_sfc vars_out  testset  kernel_sizes  channels  \\\n",
       "0     conv2d   tpsuvq  subset-cyc        q        2             1       128   \n",
       "1     conv2d   tpsuvq  subset-cyc        q        2             1       128   \n",
       "2     conv2d   tpsuvq  subset-cyc        t        2             1       128   \n",
       "3     conv2d   tpsuvq  subset-cyc        t        2             1       128   \n",
       "4     conv2d   tpsuvq  subset-cyc        u        2             1       128   \n",
       "5     conv2d   tpsuvq  subset-cyc        u        2             1       128   \n",
       "6     conv2d   tpsuvq  subset-cyc        v        2             1       128   \n",
       "7     conv2d   tpsuvq  subset-cyc        v        2             1       128   \n",
       "\n",
       "   n_conv     p  bs loss       lr    wd trunc  \\\n",
       "0       2  0.25   8  mse  0.00001  0.01   sub   \n",
       "1       2  0.25   8  mse  0.00001  0.05   sub   \n",
       "2       2  0.25   8  mse  0.00001  0.01   sub   \n",
       "3       2  0.25   8  mse  0.00001  0.05   sub   \n",
       "4       2  0.25   8  mse  0.00001  0.01   sub   \n",
       "5       2  0.25   8  mse  0.00001  0.05   sub   \n",
       "6       2  0.25   8  mse  0.00001  0.01   sub   \n",
       "7       2  0.25   8  mse  0.00001  0.05   sub   \n",
       "\n",
       "                                            filename  epoches  impatience  \\\n",
       "0  /home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...      500           0   \n",
       "1  /home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...      500           0   \n",
       "2  /home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...      500           0   \n",
       "3  /home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...      500           0   \n",
       "4  /home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...      500           0   \n",
       "5  /home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...      500           0   \n",
       "6  /home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...      500           0   \n",
       "7  /home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-...      500           0   \n",
       "\n",
       "   valid_min  \n",
       "0   0.012005  \n",
       "1   0.012005  \n",
       "2   0.012008  \n",
       "3   0.012008  \n",
       "4   0.012109  \n",
       "5   0.012109  \n",
       "6   0.012187  \n",
       "7   0.012187  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data frame allows for versatile viewing of the collected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [128], [2], [0.25], [1e-05], [0.01, 0.05]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(np.unique(df[i],axis=0)) for i in ['kernel_sizes','channels','n_conv','p','lr','wd',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernel_sizes  n_conv  channels  bs  trunc\n",
       "1             2       128       8   sub      0.012008\n",
       "Name: valid_min, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.vars_out=='t')].groupby(['kernel_sizes', 'n_conv','channels','bs', 'trunc']).valid_min.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column NN, subsampled dataset\n",
    "- find and evaluate (using testing dataset) the models having minimal validation loss for each variable\n",
    "- run command once with if_renew=True, and then once with if_renew=False:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:t\n",
      "INFO:root:/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-crct//checks/conv2d_tpsuvq_subset-cyc_t_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:model evaled before. reading from file.\n",
      "INFO:root:finished\n",
      "INFO:root:Learned percentage: 0.023318111896514893\n",
      "INFO:root:R2:  0.023318111896514893\n",
      "INFO:root:MSE: 0.9766820073127747\n",
      "INFO:root:MSE: 0.9766820073127747\n",
      "INFO:root:q\n",
      "INFO:root:/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-crct//checks/conv2d_tpsuvq_subset-cyc_q_2_1_128_2_0.25_8_mse_1e-05_0.05_sub\n",
      "INFO:root:model evaled before. reading from file.\n",
      "INFO:root:finished\n",
      "INFO:root:Learned percentage: 0.02360433340072632\n",
      "INFO:root:R2:  0.02360433340072632\n",
      "INFO:root:MSE: 0.9763954877853394\n",
      "INFO:root:MSE: 0.9763954877853394\n",
      "INFO:root:u\n",
      "INFO:root:/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-crct//checks/conv2d_tpsuvq_subset-cyc_u_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:model evaled before. reading from file.\n",
      "INFO:root:finished\n",
      "INFO:root:Learned percentage: 0.015153765678405762\n",
      "INFO:root:R2:  0.015153765678405762\n",
      "INFO:root:MSE: 0.9848462343215942\n",
      "INFO:root:MSE: 0.9848462343215942\n",
      "INFO:root:v\n",
      "INFO:root:/home/Tse-chun.Chen/anal_inc/rply-inc-mdl-err-crct//checks/conv2d_tpsuvq_subset-cyc_v_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:model evaled before. reading from file.\n",
      "INFO:root:finished\n",
      "INFO:root:Learned percentage: 0.008795201778411865\n",
      "INFO:root:R2:  0.008795201778411865\n",
      "INFO:root:MSE: 0.9912047982215881\n",
      "INFO:root:MSE: 0.9912047982215881\n"
     ]
    }
   ],
   "source": [
    "if_renew=False\n",
    "for var in ['t','q','u','v']: # loop through variables\n",
    "    time.sleep(10)\n",
    "    filename = df[(df.vars_out==var)].sort_values('valid_min').iloc[0].filename # find model that has minimal validation loss\n",
    "    logging.info(var)\n",
    "    logging.info(filename)\n",
    "    if if_renew:\n",
    "        sub_eval_model(filename,if_renew=True,if_wait=False) # submit evaluation\n",
    "        #print(filename)\n",
    "    else:\n",
    "        y_pred, y=sub_eval_model(filename,if_renew=False,if_wait=True) # read from previous evaluation (if exists) and output\n",
    "        logging.info(\"MSE: {}\".format(np.mean((y-y_pred)**2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- expect output prediction \"y_pred_\\*\" and truth \"y_\\*\" for testing period in \"./npys/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./npys/y*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliency map\n",
    "- compute the averaged gradients of the models using the checkpoint files\n",
    "- run command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "J = []\n",
    "checks = ['./checks/conv2d_tpsuvq_online_t_3_1_4096_3_0.25_8_mse_0.0001_0.05_sub',\n",
    "          './checks/conv2d_tpsuvq_online_q_3_1_4096_3_0.25_8_mse_0.0001_0.05_sub',\n",
    "          './checks/conv2d_tpsuvq_online_u_3_1_4096_3_0.25_8_mse_0.0001_0.05_sub',\n",
    "          './checks/conv2d_tpsuvq_online_v_3_1_4096_3_0.25_8_mse_0.0001_0.05_sub'] # compute from the checkpoint files\n",
    "\n",
    "for filename in checks:\n",
    "    J.append(sub_saliency(filename=filename, if_renew=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- takes 15 mins\n",
    "- expect output in \"./npys\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./npys/J*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_all = np.concatenate(J) # put the gradients for differents variables together\n",
    "\n",
    "# reorganize for T,Q,U,V\n",
    "J_TQUV = np.zeros((508,508))\n",
    "J_TQUV[:,0:127] = J_all[:,0:127]\n",
    "J_TQUV[:,0+127*1:0+127*2] = J_all[:,1+127*3:1+127*4]\n",
    "J_TQUV[:,0+127*2:0+127*4] = J_all[:,1+127*1:1+127*3]\n",
    "\n",
    "# reorganize for boundary condition\n",
    "J_bc = np.zeros((508,15))\n",
    "J_bc[:,0] = J_all[:,127]\n",
    "J_bc[:,1:15] = J_all[:,-14:]\n",
    "\n",
    "# make yticks for plot\n",
    "sample = xr.open_dataset('./sample_nc/2019122000/sfg_2019122000_fhr00_control')\n",
    "pfulls = [1000, 850,500,150,10,0.01]\n",
    "yticks = (np.interp(pfulls, sample.pfull.values,range(127),),pfulls)\n",
    "yticks_0 = np.concatenate([yticks[0], yticks[0][:-1]+127, yticks[0][:-1]+127*2, yticks[0][:-1]+127*3,])\n",
    "yticks_1 = yticks[1] + yticks[1][:-1]*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.cm.get_cmap('PiYG',22)\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(J_TQUV.T, cmap=cmap,vmax=0.1,vmin=-0.1\n",
    "           #norm=colors.SymLogNorm(linthresh=0.05, linscale=1,\n",
    "           #                                   vmin=-1, vmax=1)\n",
    "          )\n",
    "lw=0.5\n",
    "c='0.3'\n",
    "plt.axvline(126,c=c,lw=lw)\n",
    "plt.axvline(126+127*1,c=c,lw=lw)\n",
    "plt.axvline(126+127*2,c=c,lw=lw)\n",
    "plt.axhline(126,c=c,lw=lw)\n",
    "plt.axhline(126+127*1,c=c,lw=lw)\n",
    "plt.axhline(126+127*2,c=c,lw=lw)\n",
    "\n",
    "plt.yticks(yticks_0, yticks_1)\n",
    "plt.xticks(yticks_0, yticks_1, rotation='45',ha='right')\n",
    "\n",
    "plt.colorbar(aspect=40)\n",
    "#plt.ylabel('Input\\n forecast\\n [hPa]',rotation='0', ha='right')\n",
    "#plt.xlabel('Output correction [hPa]')\n",
    "for i in range(4):\n",
    "    plt.text([63,63+127,63+127*2,63+127*3][i], 508+40, f\"Output: {['T','Q','U','V'][i]} inc.\",fontsize=20, ha='center')\n",
    "    plt.text([63,63+127,63+127*2,63+127*3][i], -8, f\"Column NN for\\n {['T','Q','U','V'][i]} prediction\",fontsize=20, ha='center')\n",
    "    plt.text(-40, [63,63+127,63+127*2,63+127*3][i], f\"Input:\\n {['T','Q','U','V'][i]} fcst\",fontsize=20, ha='right')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make yticks\n",
    "yticks_bc=np.array(['log(surface pressure)',\n",
    "                    'clear sky downward long wave flux','clear sky downward short wave flux',\n",
    "                    'clear sky upward long wave flux', 'clear sky upward long wave flux at toa',\n",
    "                    'clear sky upward short wave flux', 'clear sky upward short wave flux at toa',\n",
    "                    'land-sea-ice mask', 'latitude','sin(longitude)','cos(longitude)',\n",
    "                    'sin(hour of the day)','sin(day of the year)','cos(hour of the day)','cos(day of the year)', ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.cm.get_cmap('PiYG',22)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(J_bc.T,cmap=cmap,aspect='auto', interpolation='nearest',\n",
    "           #norm=colors.SymLogNorm(linthresh=0.05, linscale=1,\n",
    "           #                                   vmin=-1, vmax=1)\n",
    "          )\n",
    "lw=0.5\n",
    "c='0.3'\n",
    "plt.axvline(126,c=c,lw=lw)\n",
    "plt.axvline(126+127*1,c=c,lw=lw)\n",
    "plt.axvline(126+127*2,c=c,lw=lw)\n",
    "plt.xticks(yticks_0, yticks_1, rotation='45',ha='right')\n",
    "plt.yticks(range(15),yticks_bc,)\n",
    "for i in range(4):\n",
    "    plt.text([63,63+127,63+127*2,63+127*3][i], 32, f\"Output: {['T','Q','U','V'][i]} inc.\",fontsize=20, ha='center',va='top')\n",
    "    plt.text([63,63+127,63+127*2,63+127*3][i], -1, f\"Column NN for\\n {['T','Q','U','V'][i]} prediction\",fontsize=20, ha='center')\n",
    "    \n",
    "plt.colorbar(aspect=30)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output NN to nc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from check_model import model_to_nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:t\n",
      "INFO:root:checks/conv2d_tpsuvq_subset-cyc_t_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:################################################\n",
      "INFO:root:## output coeff. to nc file                     \n",
      "INFO:root:################################################\n",
      "INFO:root:[537, 128, 127]\n",
      "INFO:root:################################################\n",
      "INFO:root:## read_hyperparam                              \n",
      "INFO:root:################################################\n",
      "INFO:root:checks/conv2d_tpsuvq_subset-cyc_t_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:################################################\n",
      "INFO:root:## Get_train_param_name                         \n",
      "INFO:root:################################################\n",
      "INFO:root:################################################\n",
      "INFO:root:## get_test_dataset                             \n",
      "INFO:root:################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel in  size: 537\n",
      "Channel out size: 127\n",
      "Time snapshots: 1867\n",
      "time preparing data: 42.80714511871338s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    title: NN coefficients\n",
      "    subtitle: checks/conv2d_tpsuvq_subset-cyc_t_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "    nn_sizes: [537 128 127]\n",
      "    var_out: t\n",
      "    dimensions(sizes): layer0(537), layer1(128), layer2(127)\n",
      "    variables(dimensions): float32 w0(layer0, layer1), float32 b0(layer1), float32 w1(layer1, layer2), float32 b1(layer2)\n",
      "    groups: \n",
      "INFO:root:q\n",
      "INFO:root:checks/conv2d_tpsuvq_subset-cyc_q_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:################################################\n",
      "INFO:root:## output coeff. to nc file                     \n",
      "INFO:root:################################################\n",
      "INFO:root:[537, 128, 127]\n",
      "INFO:root:################################################\n",
      "INFO:root:## read_hyperparam                              \n",
      "INFO:root:################################################\n",
      "INFO:root:checks/conv2d_tpsuvq_subset-cyc_q_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:################################################\n",
      "INFO:root:## Get_train_param_name                         \n",
      "INFO:root:################################################\n",
      "INFO:root:################################################\n",
      "INFO:root:## get_test_dataset                             \n",
      "INFO:root:################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel in  size: 537\n",
      "Channel out size: 127\n",
      "Time snapshots: 1867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    title: NN coefficients\n",
      "    subtitle: checks/conv2d_tpsuvq_subset-cyc_q_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "    nn_sizes: [537 128 127]\n",
      "    var_out: q\n",
      "    dimensions(sizes): layer0(537), layer1(128), layer2(127)\n",
      "    variables(dimensions): float32 w0(layer0, layer1), float32 b0(layer1), float32 w1(layer1, layer2), float32 b1(layer2)\n",
      "    groups: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time preparing data: 50.1672739982605s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:u\n",
      "INFO:root:checks/conv2d_tpsuvq_subset-cyc_u_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:################################################\n",
      "INFO:root:## output coeff. to nc file                     \n",
      "INFO:root:################################################\n",
      "INFO:root:[537, 128, 127]\n",
      "INFO:root:################################################\n",
      "INFO:root:## read_hyperparam                              \n",
      "INFO:root:################################################\n",
      "INFO:root:checks/conv2d_tpsuvq_subset-cyc_u_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:################################################\n",
      "INFO:root:## Get_train_param_name                         \n",
      "INFO:root:################################################\n",
      "INFO:root:################################################\n",
      "INFO:root:## get_test_dataset                             \n",
      "INFO:root:################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel in  size: 537\n",
      "Channel out size: 127\n",
      "Time snapshots: 1867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    title: NN coefficients\n",
      "    subtitle: checks/conv2d_tpsuvq_subset-cyc_u_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "    nn_sizes: [537 128 127]\n",
      "    var_out: u\n",
      "    dimensions(sizes): layer0(537), layer1(128), layer2(127)\n",
      "    variables(dimensions): float32 w0(layer0, layer1), float32 b0(layer1), float32 w1(layer1, layer2), float32 b1(layer2)\n",
      "    groups: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time preparing data: 42.523711919784546s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:v\n",
      "INFO:root:checks/conv2d_tpsuvq_subset-cyc_v_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:################################################\n",
      "INFO:root:## output coeff. to nc file                     \n",
      "INFO:root:################################################\n",
      "INFO:root:[537, 128, 127]\n",
      "INFO:root:################################################\n",
      "INFO:root:## read_hyperparam                              \n",
      "INFO:root:################################################\n",
      "INFO:root:checks/conv2d_tpsuvq_subset-cyc_v_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "INFO:root:################################################\n",
      "INFO:root:## Get_train_param_name                         \n",
      "INFO:root:################################################\n",
      "INFO:root:################################################\n",
      "INFO:root:## get_test_dataset                             \n",
      "INFO:root:################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel in  size: 537\n",
      "Channel out size: 127\n",
      "Time snapshots: 1867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    title: NN coefficients\n",
      "    subtitle: checks/conv2d_tpsuvq_subset-cyc_v_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\n",
      "    nn_sizes: [537 128 127]\n",
      "    var_out: v\n",
      "    dimensions(sizes): layer0(537), layer1(128), layer2(127)\n",
      "    variables(dimensions): float32 w0(layer0, layer1), float32 b0(layer1), float32 w1(layer1, layer2), float32 b1(layer2)\n",
      "    groups: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time preparing data: 37.786083936691284s\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    var = ['t','q','u','v'][i]\n",
    "    filename = [\"checks/conv2d_tpsuvq_subset-cyc_t_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\",\n",
    "                \"checks/conv2d_tpsuvq_subset-cyc_q_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\",\n",
    "                \"checks/conv2d_tpsuvq_subset-cyc_u_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\",\n",
    "                \"checks/conv2d_tpsuvq_subset-cyc_v_2_1_128_2_0.25_8_mse_1e-05_0.01_sub\"][i]\n",
    "    logging.info(var)\n",
    "    logging.info(filename)\n",
    "    \n",
    "    model_to_nc(filename, if_return_nc=False, if_norm=True)\n",
    "    \n",
    "    name = f\"./nn_{var}.nc\"\n",
    "    %mv nn.nc $name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./nn_q.nc  ./nn_t.nc  ./nn_u.nc  ./nn_v.nc\n"
     ]
    }
   ],
   "source": [
    "!ls ./nn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bebdf30b807d4d990425d374d201f6d6d358a52a1abaf7e2539f1d1de726c305"
  },
  "kernelspec": {
   "display_name": "Python [conda env:ltn]",
   "language": "python",
   "name": "conda-env-ltn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
